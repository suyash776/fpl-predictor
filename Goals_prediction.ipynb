{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the libraries that will be used throughout the examination of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important Libraries used by all\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Import library for split and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import for linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Import for PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Import for Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Import for Decision Tree Reg\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Import for K-Fold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# K-Fold cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Import for normalizing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import for finding the error of the model\n",
    "from sklearn import metrics\n",
    "\n",
    "# Import for Polynomial Regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#Backward Elimination\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#K-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Applying PCA\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the premier league data set and clean it up so it can be examined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-2-b3b8399c2243>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-b3b8399c2243>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "# Loading in the data set being used\n",
    "dataset = pd.read_csv('complete_gws.csv', encoding=\"ISO-8859-1\")\n",
    "dataset_test = pd.read_csv('complete_gws.csv', encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Clean up the data\n",
    "# DROP VALUES:\n",
    "dataset.drop([\"name\", \"kickoff_time\", \"kickoff_time_formatted\"], axis=1, inplace=True)\n",
    "\n",
    "dataset_test.drop([\"name\", \"kickoff_time\", \"kickoff_time_formatted\"], axis=1, inplace=True)\n",
    "\n",
    "#dataset_all.drop([\"name\", \"kickoff_time\", \"kickoff_time_formatted\"], axis=1, inplace=True)\n",
    "\n",
    "#dataset_test_all.drop([\"name\", \"kickoff_time\", \"kickoff_time_formatted\"], axis=1, inplace=True)\n",
    "         \n",
    "# Remove bad instances located near bottom of set\n",
    "dataset=dataset.iloc[:67936,:]\n",
    "\n",
    "# Remove all players with minutes = 0\n",
    "dataset = dataset[dataset.minutes!=0]\n",
    "\n",
    "# c=dataset_test.columns\n",
    "# print(c[46])\n",
    "\n",
    "# Set the target y as goal_scored and x as remaining columns\n",
    "dataset_test.drop([\"goals_scored\"], axis=1, inplace=True)\n",
    "X = dataset.iloc[:,dataset.columns != \"goals_scored\"].values\n",
    "y = dataset.iloc[:,dataset.columns == \"goals_scored\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split for train(.70) and test(.30) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets examine the data before setting it to the different models selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_goals = np.unique(y_train, return_counts=True)\n",
    "\n",
    "print(total_goals[1])\n",
    "plt.bar(total_goals[0],total_goals[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Fitting the data to a Multiple Linear Regression Model Without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the data to a Multiple Linear Regression Model\n",
    "\n",
    "# Fitting the multiple linear regresion to the training set\n",
    "mlr_obj_no_norm = LinearRegression()\n",
    "mlr_obj_no_norm.fit(X_train, y_train)\n",
    "\n",
    "num_culmn_raw  = X_train[0,:]\n",
    "\n",
    "print(\"The weight parameters are:\")\n",
    "\n",
    "for idx, col_name in enumerate(dataset_test.columns[:len(num_culmn_raw)]):\n",
    "    print(\"({}) {}: {}\".format(idx, col_name, mlr_obj_no_norm.coef_[0][idx]).sorted())\n",
    "\n",
    "# Predicting on the test set\n",
    "mlr_y_pred_no_norm = mlr_obj_no_norm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Mean Squared Error for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Squared Error for MLR:\", metrics.mean_squared_error(y_test, mlr_y_pred_no_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the data to make sure no one variable pulls to much on the prediction. (Do We Need to Normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the features\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the data to a Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting the multiple linear regresion to the training set\n",
    "mlr_obj = LinearRegression()\n",
    "mlr_obj.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "num_culmn_raw  = X_train[0,:]\n",
    "\n",
    "print(\"The weight parameters are:\")\n",
    "\n",
    "for idx, col_name in enumerate(dataset_test.columns[:len(num_culmn_raw)]):\n",
    "    print(\"({}) {}: {}\".format(idx, col_name, mlr_obj.coef_[0][idx]))\n",
    "\n",
    "# Predicting on the test set\n",
    "mlr_y_pred = mlr_obj.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Mean Squared Error for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Squared Error for MLR:\", metrics.mean_squared_error(y_test, mlr_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using backwards elimination to trim the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwardElimination(x, sl):\n",
    "    \n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        \n",
    "        #print(\"check:\", i)\n",
    "\n",
    "        obj_OLS = sm.OLS(endog = y, exog = x).fit()\n",
    "        maxVar = max(obj_OLS.pvalues).astype(float)\n",
    "        #print(maxVar)\n",
    "\n",
    "        if maxVar > sl:\n",
    "            \n",
    "            for j in range(0, numVars - i):\n",
    "                if (obj_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    print(j)\n",
    "                    x = np.delete(x, j, 1)\n",
    "                    dataset_test.drop([dataset_test.columns[j]], axis=1, inplace=True)\n",
    "                    \n",
    "                    \n",
    "    obj_OLS.summary()\n",
    "    return x\n",
    "\n",
    "\n",
    "X = X.astype(float)\n",
    "SL = 0.05\n",
    "X_sig = X[:,:]\n",
    "X_Modeled = backwardElimination(X_sig, SL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now run the trimed data with a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_sig_train, X_sig_test, y_sig_train, y_sig_test = train_test_split(\n",
    "    X_Modeled, y, test_size = 0.3)\n",
    "\n",
    "mlr_bw_obj = LinearRegression()\n",
    "mlr_bw_obj.fit(X_sig_train, y_sig_train)\n",
    "\n",
    "y_sig_pred = mlr_bw_obj.predict(X_sig_test)\n",
    "\n",
    "num_culmn_sig  = X_Modeled[0,:]\n",
    "\n",
    "print(\"The weight parameters are:\")\n",
    "\n",
    "for idx, col_name in enumerate(dataset_test.columns[:len(num_culmn_sig)]):\n",
    "    print(\"({}) {}: {}\".format(idx, col_name, mlr_bw_obj.coef_[0][idx]))\n",
    "\n",
    "#print(\"Mean Squared Error for MLR and Backward Elimination:\", metrics.mean_squared_error(y_sig_test, y_sig_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLR and Backward Elimination Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Squared Error for MLR and Backward Elimination:\", metrics.mean_squared_error(y_sig_test, y_sig_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine a Decison Tree regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_obj = DecisionTreeRegressor()\n",
    "dtr_obj.fit(X_train, y_train)\n",
    "\n",
    "dtr_y_pred = dtr_obj.predict(X_test)\n",
    "\n",
    "print(\"Mean Squared Error for Decision Tree:\", metrics.mean_squared_error(y_test, dtr_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine a Random Forrest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tree = []\n",
    "msqe = []\n",
    "\n",
    "for n in range (10, 301, 10):\n",
    "    \n",
    "    num_tree.append(n)\n",
    "    \n",
    "    randf_obj = RandomForestRegressor(n_estimators=n)\n",
    "    randf_obj.fit(X_train, y_train)\n",
    "    \n",
    "    randf_y_pred = randf_obj.predict(X_test)\n",
    "    \n",
    "    mean_sqr_eror = metrics.mean_squared_error(y_test, \n",
    "                                               randf_y_pred)\n",
    "    \n",
    "    # print(mean_sqr_eror)\n",
    "    \n",
    "    msqe.append(mean_sqr_eror)\n",
    "    \n",
    "print('Lowest testing error =', min(msqe))\n",
    "print('Associated number of trees (n_estimator) =', \n",
    "      num_tree[msqe.index(min(msqe))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lowest testing error =', min(msqe))\n",
    "print('Associated number of trees (n_estimator) =', \n",
    "      num_tree[msqe.index(min(msqe))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA model examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tree_pca = []\n",
    "pca_error = []\n",
    "\n",
    "for n in range(1, len(num_culmn_raw)):\n",
    "    num_tree_pca.append(n)\n",
    "    \n",
    "    pca_obj = PCA(n_components=n)\n",
    "    X_PCA_train = pca_obj.fit_transform(X_train)\n",
    "    X_PCA_test = pca_obj.transform(X_test)\n",
    "    components_variance = pca_obj.explained_variance_ratio_\n",
    "\n",
    "    # Fit a linear regression to the training set\n",
    "    mlr_pca_obj = LinearRegression()\n",
    "    mlr_pca_obj.fit(X_PCA_train, y_train)\n",
    "\n",
    "    y_mlr_pca_pred = mlr_pca_obj.predict(X_PCA_test)\n",
    "    \n",
    "    pca_error.append(metrics.mean_squared_error(y_test, y_mlr_pca_pred))\n",
    "    \n",
    "    #print(n)\n",
    "    #print(metrics.mean_squared_error(y_test, y_mlr_pca_pred))\n",
    "    \n",
    "print('Lowest testing error =', min(pca_error))\n",
    "print('Associated number of components (n_components) =', \n",
    "      num_tree_pca[pca_error.index(min(pca_error))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multiple Linear Regression Raw\n",
    "modelAccuracies = cross_val_score(estimator=mlr_obj, X=X_train, y=y_train, cv=10)\n",
    "print(\"MLR Mean:\", modelAccuracies.mean())\n",
    "print(\"MLR Standard Deviation:\", modelAccuracies.std())\n",
    "\n",
    "print()\n",
    "\n",
    "# Multilinear Regression with Backward Elimination\n",
    "modelAccuracies = cross_val_score(estimator=mlr_bw_obj, X=X_train, y=y_train, cv=10)\n",
    "print(\"MLR/Backward Elimination Mean:\", modelAccuracies.mean())\n",
    "print(\"MLR/Backward Elimination Deviation:\", modelAccuracies.std())\n",
    "\n",
    "print()\n",
    "\n",
    "# Decision Tree Model\n",
    "modelAccuracies = cross_val_score(estimator=dtr_obj, X=X_train, y=y_train, cv=10)\n",
    "print(\"Decission Tree Mean:\", modelAccuracies.mean())\n",
    "print(\"Decission Tree Deviation:\", modelAccuracies.std())\n",
    "\n",
    "print()\n",
    "\n",
    "# Random Forest Model\n",
    "randf_obj = RandomForestRegressor(n_estimators=num_tree[msqe.index(min(msqe))])\n",
    "modelAccuracies = cross_val_score(estimator=randf_obj, X=X_train, y=y_train, cv=10)\n",
    "print(\"Random Forest Mean:\", modelAccuracies.mean())\n",
    "print(\"Random Forest Standard Deviation:\", modelAccuracies.std())\n",
    "\n",
    "print()\n",
    "\n",
    "# PCA Model\n",
    "modelAccuracies = cross_val_score(estimator=mlr_pca_obj, X=X_train, y=y_train, cv=5)\n",
    "print(\"MLR/PCA Mean:\", modelAccuracies.mean())\n",
    "print(\"MLR/PCA Standard Deviation:\", modelAccuracies.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
